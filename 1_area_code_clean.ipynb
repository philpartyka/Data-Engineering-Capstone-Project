{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('area_code_clean').getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the zipped dataset\n",
    "zip_data = 'source_data/full_area_code_dataset.zip'\n",
    "\n",
    "#extract zipped file\n",
    "with zipfile.ZipFile(zip_data, 'r') as zip_ref:\n",
    "    zip_ref.extractall('source_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "npa_df = spark.read.json(\"source_data/full_area_code_dataset.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains NPA numbers (area codes) from Canada as well so lets look at just the United States data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------------+----------+-----------+---------+------------+--------+---------+---+------+---+------+--------+-------+\n",
      "|                 _id|      city|      country|countryISO|dstObserved|gmtOffset|gmtOffsetDST|latitude|longitude|npa|npanxx|nxx| state|stateISO|zipCode|\n",
      "+--------------------+----------+-------------+----------+-----------+---------+------------+--------+---------+---+------+---+------+--------+-------+\n",
      "|{5a8c58ba60ca6764...|    Valdez|United States|        US|          1|       -9|          -8| 61.1381|-146.3572|907|907200|200|Alaska|      AK|  99686|\n",
      "|{5a8c58ba60ca6764...|    Juneau|United States|        US|          1|       -9|          -8| 58.2994|-134.3908|907|907209|209|Alaska|      AK|  99811|\n",
      "|{5a8c58ba60ca6764...|    Juneau|United States|        US|          1|       -9|          -8| 58.2994|-134.3908|907|907209|209|Alaska|      AK|  99803|\n",
      "|{5a8c58ba60ca6764...|      Jber|United States|        US|          1|       -9|          -8|  61.235|  -149.87|907|907212|212|Alaska|      AK|  99506|\n",
      "|{5a8c58ba60ca6764...| Ketchikan|United States|        US|          1|       -9|          -8| 55.3573|-131.6798|907|907220|220|Alaska|      AK|  99901|\n",
      "|{5a8c58ba60ca6764...|Fort Yukon|United States|        US|          1|       -9|          -8| 66.2703|-145.7978|907|907221|221|Alaska|      AK|  99740|\n",
      "|{5a8c58ba60ca6764...| Anchorage|United States|        US|          1|       -9|          -8|  61.235|  -149.87|907|907222|222|Alaska|      AK|  99503|\n",
      "|{5a8c58ba60ca6764...| Anchorage|United States|        US|          1|       -9|          -8|  61.235|  -149.87|907|907222|222|Alaska|      AK|  99501|\n",
      "|{5a8c58ba60ca6764...| Anchorage|United States|        US|          1|       -9|          -8|  61.235|  -149.87|907|907222|222|Alaska|      AK|  99508|\n",
      "|{5a8c58ba60ca6764...| Anchorage|United States|        US|          1|       -9|          -8|  61.235|  -149.87|907|907222|222|Alaska|      AK|  99504|\n",
      "+--------------------+----------+-------------+----------+-----------+---------+------------+--------+---------+---+------+---+------+--------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "npa_df.where(npa_df['country'] == \"United States\").show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove some of the unecessary columns and pick just the ones we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "npa_df = npa_df.select('city', 'countryISO', 'npa', 'stateISO', 'zipCode')\\\n",
    "    .where(npa_df['country'] == \"United States\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---+--------+-------+\n",
      "|       city|countryISO|npa|stateISO|zipCode|\n",
      "+-----------+----------+---+--------+-------+\n",
      "|     Valdez|        US|907|      AK|  99686|\n",
      "|     Juneau|        US|907|      AK|  99811|\n",
      "|     Juneau|        US|907|      AK|  99803|\n",
      "|       Jber|        US|907|      AK|  99506|\n",
      "|  Ketchikan|        US|907|      AK|  99901|\n",
      "| Fort Yukon|        US|907|      AK|  99740|\n",
      "|  Anchorage|        US|907|      AK|  99503|\n",
      "|  Anchorage|        US|907|      AK|  99501|\n",
      "|  Anchorage|        US|907|      AK|  99508|\n",
      "|  Anchorage|        US|907|      AK|  99504|\n",
      "|  Anchorage|        US|907|      AK|  99509|\n",
      "|  Anchorage|        US|907|      AK|  99502|\n",
      "|  Anchorage|        US|907|      AK|  99517|\n",
      "|  Anchorage|        US|907|      AK|  99511|\n",
      "|    Wasilla|        US|907|      AK|  99687|\n",
      "|     Willow|        US|907|      AK|  99688|\n",
      "|Eagle River|        US|907|      AK|  99577|\n",
      "|     Seward|        US|907|      AK|  99664|\n",
      "|  Ward Cove|        US|907|      AK|  99928|\n",
      "|  Ketchikan|        US|907|      AK|  99901|\n",
      "+-----------+----------+---+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "npa_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many rows are in this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365121"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npa_df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes, that's a lot of data!  I wonder if there is redundant data now that we removed the unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT city)|\n",
      "+--------------------+\n",
      "|               17342|\n",
      "+--------------------+\n",
      "\n",
      "+-------------------+\n",
      "|count(DISTINCT npa)|\n",
      "+-------------------+\n",
      "|                279|\n",
      "+-------------------+\n",
      "\n",
      "+--------------------------+\n",
      "|count(DISTINCT countryISO)|\n",
      "+--------------------------+\n",
      "|                         1|\n",
      "+--------------------------+\n",
      "\n",
      "+-----------------------+\n",
      "|count(DISTINCT zipCode)|\n",
      "+-----------------------+\n",
      "|                  34748|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "npa_df.select(F.countDistinct(\"city\")).show()\n",
    "npa_df.select(F.countDistinct(\"npa\")).show()\n",
    "npa_df.select(F.countDistinct(\"countryISO\")).show()\n",
    "npa_df.select(F.countDistinct(\"zipCode\")).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there is a lot of duplicate entries so there is a lot to trim.  Let's run the .distinct() method on the dataframe to remove all the duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "npa_df = npa_df.distinct()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how much smaller the dataframe is now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43404"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npa_df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one issue.  Some zip codes have multiple NPA numbers (area codes) associated with them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---+--------+-------+\n",
      "|     city|countryISO|npa|stateISO|zipCode|\n",
      "+---------+----------+---+--------+-------+\n",
      "| Adjuntas|        US|787|      PR|  00601|\n",
      "| Adjuntas|        US|939|      PR|  00601|\n",
      "|   Aguada|        US|787|      PR|  00602|\n",
      "|Aguadilla|        US|787|      PR|  00603|\n",
      "|  Maricao|        US|787|      PR|  00606|\n",
      "|  Maricao|        US|939|      PR|  00606|\n",
      "+---------+----------+---+--------+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "npa_df.orderBy('zipCode', 'npa').show(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets consolidate those area codes into a list so that we don't have duplicate zip code entries.  We are grouping the zipcodes and cities, aka removing the redundancies and we are performing an aggregate function on the \"npa\" column.  The function collect_list() aggregates the values into a list and we are renaming this aggregate column as \"npa\" via the alias() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "npa_df = npa_df.select(\"city\",\"zipCode\", \"npa\").groupBy(\"zipCode\", \"city\")\\\n",
    "    .agg(F.collect_list(\"npa\").alias(\"npa_list\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+\n",
      "|zipCode|     city|  npa_list|\n",
      "+-------+---------+----------+\n",
      "|  00601| Adjuntas|[939, 787]|\n",
      "|  00602|   Aguada|     [787]|\n",
      "|  00603|Aguadilla|     [787]|\n",
      "|  00606|  Maricao|[939, 787]|\n",
      "|  00610|   Anasco|     [787]|\n",
      "+-------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "npa_df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better.  Lets export this data so we can use it in the customer_etl file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark was giving me an error when I tried to save the spark dataframe to a json file so I converted it to a pandas dataframe and saved it using a pandas method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = npa_df.toPandas()\n",
    "pandas_df.to_json(\"source_data/area_codes.json\", orient='records', lines=True)\n",
    "\n",
    "# I had to use ', orient='records', lines=True\"' because the pandas .to_json function \n",
    "# saves the columns as a dictionairy entry in the json file but pyspark read.json function \n",
    "# expects each row of the dataframe to be a single line in the json file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
