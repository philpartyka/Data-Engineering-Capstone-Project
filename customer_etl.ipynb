{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('customer_etl').getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load cdw_sapp_custmer.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = spark.read.json(\"source_data/cdw_sapp_custmer.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "# Exploratory Analysis & Tranforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- APT_NO: string (nullable = true)\n",
      " |-- CREDIT_CARD_NO: string (nullable = true)\n",
      " |-- CUST_CITY: string (nullable = true)\n",
      " |-- CUST_COUNTRY: string (nullable = true)\n",
      " |-- CUST_EMAIL: string (nullable = true)\n",
      " |-- CUST_PHONE: long (nullable = true)\n",
      " |-- CUST_STATE: string (nullable = true)\n",
      " |-- CUST_ZIP: string (nullable = true)\n",
      " |-- FIRST_NAME: string (nullable = true)\n",
      " |-- LAST_NAME: string (nullable = true)\n",
      " |-- LAST_UPDATED: string (nullable = true)\n",
      " |-- MIDDLE_NAME: string (nullable = true)\n",
      " |-- SSN: long (nullable = true)\n",
      " |-- STREET_NAME: string (nullable = true)\n",
      "\n",
      "+------+----------------+------------+-------------+--------------------+----------+----------+--------+----------+---------+--------------------+-----------+---------+-----------------+\n",
      "|APT_NO|  CREDIT_CARD_NO|   CUST_CITY| CUST_COUNTRY|          CUST_EMAIL|CUST_PHONE|CUST_STATE|CUST_ZIP|FIRST_NAME|LAST_NAME|        LAST_UPDATED|MIDDLE_NAME|      SSN|      STREET_NAME|\n",
      "+------+----------------+------------+-------------+--------------------+----------+----------+--------+----------+---------+--------------------+-----------+---------+-----------------+\n",
      "|   656|4210653310061055|     Natchez|United States| AHooper@example.com|   1237818|        MS|   39120|      Alec|   Hooper|2018-04-21T12:49:...|         Wm|123456100|Main Street North|\n",
      "|   829|4210653310102868|Wethersfield|United States| EHolman@example.com|   1238933|        CT|   06109|      Etta|   Holman|2018-04-21T12:49:...|    Brendan|123453023|    Redwood Drive|\n",
      "|   683|4210653310116272|     Huntley|United States| WDunham@example.com|   1243018|        IL|   60142|    Wilber|   Dunham|2018-04-21T12:49:...|   Ezequiel|123454487| 12th Street East|\n",
      "|   253|4210653310195948|   NewBerlin|United States|  EHardy@example.com|   1243215|        WI|   53151|   Eugenio|    Hardy|2018-04-21T12:49:...|      Trina|123459758|Country Club Road|\n",
      "|   301|4210653310356919|      ElPaso|United States|  WAyers@example.com|   1242074|        TX|   79930|   Wilfred|    Ayers|2018-04-21T12:49:...|        May|123454431|   Madison Street|\n",
      "|     3|4210653310395982|NorthOlmsted|United States|BWoodard@example.com|   1242570|        OH|   44070|      Beau|  Woodard|2018-04-21T12:49:...|    Ambrose|123454202|   Colonial Drive|\n",
      "|    84|4210653310400536|      Vienna|United States|   SKemp@example.com|   1239685|        VA|   22180|    Sheila|     Kemp|2018-04-21T12:49:...|      Larry|123451799|   Belmont Avenue|\n",
      "|   728|4210653310459911|      Duarte|United States| WHurley@example.com|   1238213|        CA|   91010|     Wendy|   Hurley|2018-04-21T12:49:...|        Ora|123453875|     Oxford Court|\n",
      "|    81|4210653310773972|      Owosso|United States|AGilmore@example.com|   1240689|        MI|   48867|      Alec|  Gilmore|2018-04-21T12:49:...|     Tracie|123457511|    Forest Street|\n",
      "|   561|4210653310794854|        Zion|United States|    BLau@example.com|   1235222|        IL|   60099|    Barbra|      Lau|2018-04-21T12:49:...|    Mitchel|123457464|     Court Street|\n",
      "+------+----------------+------------+-------------+--------------------+----------+----------+--------+----------+---------+--------------------+-----------+---------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.printSchema()\n",
    "cust_df.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows do we have in total in this dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "952"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rearrange the columns so they make a bit more sense when looking at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+-------------------+----------+----------+-----------+---------+------+-----------------+------------+--------+----------+-------------+--------------------+\n",
      "|  CREDIT_CARD_NO|      SSN|         CUST_EMAIL|CUST_PHONE|FIRST_NAME|MIDDLE_NAME|LAST_NAME|APT_NO|      STREET_NAME|   CUST_CITY|CUST_ZIP|CUST_STATE| CUST_COUNTRY|        LAST_UPDATED|\n",
      "+----------------+---------+-------------------+----------+----------+-----------+---------+------+-----------------+------------+--------+----------+-------------+--------------------+\n",
      "|4210653310061055|123456100|AHooper@example.com|   1237818|      Alec|         Wm|   Hooper|   656|Main Street North|     Natchez|   39120|        MS|United States|2018-04-21T12:49:...|\n",
      "|4210653310102868|123453023|EHolman@example.com|   1238933|      Etta|    Brendan|   Holman|   829|    Redwood Drive|Wethersfield|   06109|        CT|United States|2018-04-21T12:49:...|\n",
      "|4210653310116272|123454487|WDunham@example.com|   1243018|    Wilber|   Ezequiel|   Dunham|   683| 12th Street East|     Huntley|   60142|        IL|United States|2018-04-21T12:49:...|\n",
      "|4210653310195948|123459758| EHardy@example.com|   1243215|   Eugenio|      Trina|    Hardy|   253|Country Club Road|   NewBerlin|   53151|        WI|United States|2018-04-21T12:49:...|\n",
      "|4210653310356919|123454431| WAyers@example.com|   1242074|   Wilfred|        May|    Ayers|   301|   Madison Street|      ElPaso|   79930|        TX|United States|2018-04-21T12:49:...|\n",
      "+----------------+---------+-------------------+----------+----------+-----------+---------+------+-----------------+------------+--------+----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df = cust_df.select('CREDIT_CARD_NO', 'SSN', 'CUST_EMAIL', 'CUST_PHONE',\\\n",
    "            'FIRST_NAME','MIDDLE_NAME', 'LAST_NAME', 'APT_NO', 'STREET_NAME',\\\n",
    "            'CUST_CITY', 'CUST_ZIP', 'CUST_STATE', 'CUST_COUNTRY', 'LAST_UPDATED')\n",
    "\n",
    "cust_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+------------------+----------+-----------+---------+------------------+-----------+---------+------------------+----------+-------------+--------------------+\n",
      "|summary|      CREDIT_CARD_NO|                 SSN|          CUST_EMAIL|        CUST_PHONE|FIRST_NAME|MIDDLE_NAME|LAST_NAME|            APT_NO|STREET_NAME|CUST_CITY|          CUST_ZIP|CUST_STATE| CUST_COUNTRY|        LAST_UPDATED|\n",
      "+-------+--------------------+--------------------+--------------------+------------------+----------+-----------+---------+------------------+-----------+---------+------------------+----------+-------------+--------------------+\n",
      "|  count|                 952|                 952|                 952|               952|       952|        952|      952|               952|        952|      952|               952|       952|          952|                 952|\n",
      "|   mean|4.210653353718597...|1.2345552588130252E8|                null|1239196.6649159663|      null|       null|     null| 507.3382352941176|       null|     null|36312.616596638654|      null|         null|                null|\n",
      "| stddev| 2.576300828101659E7|  2561.1858044909427|                null| 2612.648026005403|      null|       null|     null|287.20283977678935|       null|     null| 23945.49431677531|      null|         null|                null|\n",
      "|    min|    4210653310061055|           123451007|AAguilar@example.com|           1234574|      Abby|       Abby|   Abbott|                 1|10th Street|  Acworth|             01810|        AL|United States|2018-04-21T12:49:...|\n",
      "|    max|    4210653399939240|           123459988|ZStratton@example...|           1243558|     Zelma|    Zachary|   Zapata|               998|York Street|     Zion|             98908|        WI|United States|2018-04-21T12:49:...|\n",
      "+-------+--------------------+--------------------+--------------------+------------------+----------+-----------+---------+------------------+-----------+---------+------------------+----------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.describe().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above summary we can see that the credit card numbers are all 16 digits long, SSN numbers are all 9 digits long, zip codes are all 5 digits long, and all the customers are from the United States.  The only issue is that the phone numbers are only 7 digits long but should be 10 digits. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the CUST_ZIP and CUST_STATE columns are in string format so the min and max values might only consider the first character when considering order of values.  Lets confirm that the states are 2 characters in length and the zip codes are all 5 digits long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|zip_len|count|\n",
      "+-------+-----+\n",
      "|      5|  952|\n",
      "+-------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|state_len|count|\n",
      "+---------+-----+\n",
      "|        2|  952|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.withColumn(\"zip_len\", F.length(cust_df[\"CUST_ZIP\"]))\\\n",
    "    .groupBy(\"zip_len\").count().show()\n",
    "\n",
    "cust_df.withColumn(\"state_len\", F.length(cust_df[\"CUST_STATE\"]))\\\n",
    "    .groupBy(\"state_len\").count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make sure the emails are all valid. All have a \"@\" and a \".\" (for example, \".com\") and no blank spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|CUST_EMAIL|\n",
      "+----------+\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "email_filter_df = cust_df.filter(~F.col('CUST_EMAIL').rlike('^\\S+@\\S+\\.\\S+$'))\n",
    "email_filter_df.select('CUST_EMAIL').show()\n",
    "\n",
    "#^\\S+@\\S+\\.\\S+$ checks to see if the string is a valid email address.  the \"^\\S+\" checks\n",
    "#if there are one or more non-whitespace characters at the start of the string.  Can't have\n",
    "#blank spaces in an email address. The ^ is necessary because \"ex ample@example.com\" would be\n",
    "#a match on \"ample@example.com\".  We check for \"@\" with one or more non-whitespace character after it\n",
    "#followed by a \".\" (\\. needs to be used because just a \".\" in regex matches to any single character).\n",
    "#Finished off by \"\\S+$\" which matches one or more non-whitespace characters that end the string.  \n",
    "#The \"$\" is necessary for the same reason that the \"^\" is necessary.  The \"~\" is like a NOT so only\n",
    "#the non matches will be shown."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The customer cities look bunched up, aka two word cities have no spaces between the words.  Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|   CUST_CITY|\n",
      "+------------+\n",
      "|     Natchez|\n",
      "|Wethersfield|\n",
      "|     Huntley|\n",
      "|  New Berlin|\n",
      "|     El Paso|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df = cust_df.withColumn('CUST_CITY', \n",
    "        F.regexp_replace(cust_df['CUST_CITY'], \"(?<=.)([A-Z])\", ' $1'))\n",
    "cust_df.select('CUST_CITY').show(5)\n",
    "\n",
    "#(?<=.) is a positive lookbehind.  It checks if there is any character behind ([A-Z]).  Don't\n",
    "#want to match the capital letters in the beginning of the string.\n",
    "#([A-Z]) looks for any capital letter.  In parantheses because we want to capture this group.\n",
    "#' $1' Blank space plus the first, and only, captured group. aka this returns the matched \n",
    "#capital letter, otherwise the matched capital letter would have been replaced."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure all the CC numbers, SSNs, Phone numbers, and Emails are unique. Remember, there are 952 total entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|count(DISTINCT CREDIT_CARD_NO)|\n",
      "+------------------------------+\n",
      "|                           952|\n",
      "+------------------------------+\n",
      "\n",
      "+-------------------+\n",
      "|count(DISTINCT SSN)|\n",
      "+-------------------+\n",
      "|                952|\n",
      "+-------------------+\n",
      "\n",
      "+--------------------------+\n",
      "|count(DISTINCT CUST_PHONE)|\n",
      "+--------------------------+\n",
      "|                       901|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.select(F.countDistinct(\"CREDIT_CARD_NO\")).show()\n",
    "cust_df.select(F.countDistinct(\"SSN\")).show()\n",
    "cust_df.select(F.countDistinct(\"CUST_PHONE\")).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, the Phone numbers don't seem to be unique.  Let's explore further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|CUST_PHONE|count|\n",
      "+----------+-----+\n",
      "|   1241898|    3|\n",
      "|   1236886|    3|\n",
      "|   1237294|    3|\n",
      "|   1240382|    2|\n",
      "|   1243459|    2|\n",
      "|   1239063|    2|\n",
      "|   1242677|    2|\n",
      "|   1235508|    2|\n",
      "|   1242999|    2|\n",
      "|   1239668|    2|\n",
      "+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.groupBy('CUST_PHONE').count().orderBy(F.col('count').desc()).show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a sample phone number to see if any of the other customer info overlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+--------------------+----------+----------+-----------+---------+------+--------------+---------+--------+----------+-------------+--------------------+\n",
      "|  CREDIT_CARD_NO|      SSN|          CUST_EMAIL|CUST_PHONE|FIRST_NAME|MIDDLE_NAME|LAST_NAME|APT_NO|   STREET_NAME|CUST_CITY|CUST_ZIP|CUST_STATE| CUST_COUNTRY|        LAST_UPDATED|\n",
      "+----------------+---------+--------------------+----------+----------+-----------+---------+------+--------------+---------+--------+----------+-------------+--------------------+\n",
      "|4210653315752398|123455638|FMeredith@example...|   1236886|   Francis|    Donnell| Meredith|   417|Lincoln Street| Wilmette|   60091|        IL|United States|2018-04-21T12:49:...|\n",
      "|4210653352401004|123456941|  EWells@example.com|   1236886|     Edwin|      Alice|    Wells|   890|    5th Avenue|Mundelein|   60060|        IL|United States|2018-04-21T12:49:...|\n",
      "|4210653399859149|123454047| EBeatty@example.com|   1236886|     Emery|    Susanna|   Beatty|    15|    8th Street|  Rowlett|   75088|        TX|United States|2018-04-21T12:49:...|\n",
      "+----------------+---------+--------------------+----------+----------+-----------+---------+------+--------------+---------+--------+----------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.where(cust_df['CUST_PHONE'] == '1236886').show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample it seems like 3 different people have the same number. I would consider using an area code that corresponds to the customer's location but in this example two of the customers are in the same state and fall under the same area code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add an area code to the phone numbers based on the customer's zip code and see if that helps differentiate the data.  First, lets load the area code data into a dataframe.  I cleaned up and created this file in the \"area_code_data\" notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+\n",
      "|     city|  npa_list|zipCode|\n",
      "+---------+----------+-------+\n",
      "| Adjuntas|[939, 787]|  00601|\n",
      "|   Aguada|     [787]|  00602|\n",
      "|Aguadilla|     [787]|  00603|\n",
      "|  Maricao|[939, 787]|  00606|\n",
      "|   Anasco|     [787]|  00610|\n",
      "+---------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "area_code_df = spark.read.json(\"source_data/area_codes.json\")\n",
    "area_code_df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there can be multiple NPA numbers (area codes) for some individual zip codes and there are multiple customers from the same zip code, I decided to alternate the distribution of area codes.  When I would take an area code from the list in the npa_list column, I would move it to the back of the list so that I could just pull the first value in that list for every subsequent query.\n",
    "\n",
    "To achieve this, I first converted the area_code_df to a pandas dataframe.  I tried to implement this in a spark dataframe at first but it was running way too slow.  The reason being, in order to update the list in the npa_list column of the spark df, I had to update the entire column and dataframe, even though I just needed to update one cell.  Pandas allows for single cell updates and at a much faster speed.  The spark dataframe took 20 minutes and was only 80% completed before it got hung up indefinitely.  The same task in pandas only took 7 seconds to complete.\n",
    "\n",
    "In the below code I am interating through each row of the cust_df spark dataframe and looking at the zip code in that row.  Then I am looking up the zipcode in the pandas dataframe.  If it finds a match then I am adding the first npa from the npa_list list to a running list called area_code_list.  This list will later get added to the spark dataframe which had to be done this way because you can change a row value in a column one row at a time, in spark dfs you have to update the entire dataframe every time you want to make a change to it.  Then I place the first npa number to the end of the list and save that reordered list to the pandas df using this line: ```npa_list.append(npa_list.pop(0))```\n",
    "\n",
    "There is also an issue where some users in the customer data have a zip code that doesn't exist in the area_code dataset.  I assigned a ```None``` value to those users for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_code_pd = area_code_df.toPandas()\n",
    "\n",
    "# This empty list will contain the chosen NPA number for each row.  It will later be joined to \n",
    "# the spark dataframe as a new column.\n",
    "area_code_list = []\n",
    "\n",
    "# We are taking each row of the customer dataframe and extracting the zipcode and city for the \n",
    "# chosen customer.  \n",
    "for row in cust_df.collect():  #have to use collect.  collect() returns a list of rows.  you can \n",
    "    # iterate over this list.  if you don't use the collect() it will return a column object which \n",
    "    # can't be iterated over.\n",
    "    \n",
    "    zip_code = row[10]\n",
    "    city = row[9]\n",
    "\n",
    "    # Here we are saving the npa_list list into a npa_list variable and then taking the first \n",
    "    # object in that list and appending it to the running list we created before the for loop.\n",
    "    # Since there are some customer's with zip codes that don't match the area_code dataframe\n",
    "    # we try to find a matching NPA number based on their city.\n",
    "    try:\n",
    "        npa_list = area_code_pd.loc[area_code_pd['zipCode'] == zip_code, 'npa_list'].iloc[0]\n",
    "        area_code_list.append(npa_list[0])\n",
    "        index_pos = area_code_pd[area_code_pd['zipCode'] == zip_code].index[0]\n",
    "    except:\n",
    "        npa_list = area_code_pd.loc[area_code_pd['city'] == city, 'npa_list'].iloc[0]\n",
    "        area_code_list.append(npa_list[0])\n",
    "        index_pos = area_code_pd[area_code_pd['city'] == city].index[0]\n",
    "\n",
    "    # Below two lines reorders the python list of npa nums so that the first num goes to the back\n",
    "    # of the list.  The next line assigns this reordered list to the position of the original\n",
    "    # npa list in the pandas dataframe.\n",
    "    npa_list.append(npa_list.pop(0))\n",
    "    area_code_pd.at[index_pos, 'npa_list'] = npa_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the list is the same length as the customer dataframe (952) so there aren't any errors when we add it as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "952"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(area_code_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's join the list of NPA numbers to the customer dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+--------------------+----------+----------+-----------+---------+------+-----------------+-------------+--------+----------+-------------+--------------------+---+\n",
      "|  CREDIT_CARD_NO|      SSN|          CUST_EMAIL|CUST_PHONE|FIRST_NAME|MIDDLE_NAME|LAST_NAME|APT_NO|      STREET_NAME|    CUST_CITY|CUST_ZIP|CUST_STATE| CUST_COUNTRY|        LAST_UPDATED|npa|\n",
      "+----------------+---------+--------------------+----------+----------+-----------+---------+------+-----------------+-------------+--------+----------+-------------+--------------------+---+\n",
      "|4210653310061055|123456100| AHooper@example.com|   1237818|      Alec|         Wm|   Hooper|   656|Main Street North|      Natchez|   39120|        MS|United States|2018-04-21T12:49:...|601|\n",
      "|4210653310102868|123453023| EHolman@example.com|   1238933|      Etta|    Brendan|   Holman|   829|    Redwood Drive| Wethersfield|   06109|        CT|United States|2018-04-21T12:49:...|860|\n",
      "|4210653310116272|123454487| WDunham@example.com|   1243018|    Wilber|   Ezequiel|   Dunham|   683| 12th Street East|      Huntley|   60142|        IL|United States|2018-04-21T12:49:...|224|\n",
      "|4210653310195948|123459758|  EHardy@example.com|   1243215|   Eugenio|      Trina|    Hardy|   253|Country Club Road|   New Berlin|   53151|        WI|United States|2018-04-21T12:49:...|262|\n",
      "|4210653310356919|123454431|  WAyers@example.com|   1242074|   Wilfred|        May|    Ayers|   301|   Madison Street|      El Paso|   79930|        TX|United States|2018-04-21T12:49:...|915|\n",
      "|4210653310395982|123454202|BWoodard@example.com|   1242570|      Beau|    Ambrose|  Woodard|     3|   Colonial Drive|North Olmsted|   44070|        OH|United States|2018-04-21T12:49:...|440|\n",
      "|4210653310400536|123451799|   SKemp@example.com|   1239685|    Sheila|      Larry|     Kemp|    84|   Belmont Avenue|       Vienna|   22180|        VA|United States|2018-04-21T12:49:...|202|\n",
      "|4210653310459911|123453875| WHurley@example.com|   1238213|     Wendy|        Ora|   Hurley|   728|     Oxford Court|       Duarte|   91010|        CA|United States|2018-04-21T12:49:...|626|\n",
      "|4210653310773972|123457511|AGilmore@example.com|   1240689|      Alec|     Tracie|  Gilmore|    81|    Forest Street|       Owosso|   48867|        MI|United States|2018-04-21T12:49:...|517|\n",
      "|4210653310794854|123457464|    BLau@example.com|   1235222|    Barbra|    Mitchel|      Lau|   561|     Court Street|         Zion|   60099|        IL|United States|2018-04-21T12:49:...|224|\n",
      "+----------------+---------+--------------------+----------+----------+-----------+---------+------+-----------------+-------------+--------+----------+-------------+--------------------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#had to use pandas because adding a list in pandas is super easy.  in pyspark I would have to \n",
    "#create a dataframe for the python list and add an incrementing index column for both dataframes \n",
    "#and then join them on the index column and then drop that column.\n",
    "\n",
    "pandas_cust = cust_df.toPandas()\n",
    "pandas_cust['npa'] = area_code_list\n",
    "cust_df = spark.createDataFrame(pandas_cust)\n",
    "cust_df.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a sample zip code and see if the NPA numbers were assigned in an alternating fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---+\n",
      "|CUST_ZIP|FIRST_NAME|npa|\n",
      "+--------+----------+---+\n",
      "|   01810|   Janelle|781|\n",
      "|   01810|   Pearlie|978|\n",
      "|   01810|    Prince|617|\n",
      "|   01810|     Elmer|781|\n",
      "|   01810|     Dusty|978|\n",
      "|   01810|   Allison|617|\n",
      "|   01810|   Liliana|781|\n",
      "|   01810|     Tanya|978|\n",
      "|   01810|  Isabella|617|\n",
      "|   01810|  Courtney|781|\n",
      "|   01810|  Mckinley|978|\n",
      "|   01810|   Jacinto|617|\n",
      "+--------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.select(\"CUST_ZIP\",\"FIRST_NAME\",\"npa\").where(cust_df['CUST_ZIP'] == \"01810\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many duplicate numbers there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+-----+\n",
      "|CUST_PHONE|npa|count|\n",
      "+----------+---+-----+\n",
      "|   1238106|412|    2|\n",
      "|   1240339|310|    1|\n",
      "|   1241408|262|    1|\n",
      "|   1241213|310|    1|\n",
      "|   1239268|406|    1|\n",
      "|   1236077|469|    1|\n",
      "|   1242570|440|    1|\n",
      "|   1238165|915|    1|\n",
      "|   1236561|770|    1|\n",
      "|   1240689|517|    1|\n",
      "+----------+---+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.groupBy('CUST_PHONE','npa').count().orderBy(F.col('count').desc()).show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big improvement!  Let's investigate further to see if we can fix the last duplicate phone number.  Let's look at the zip codes for the two 1238106 numbers and then lets see if there is an alternative npa available for that zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+-------------------+----------+----------+-----------+---------+------+---------------+-----------+--------+----------+-------------+--------------------+---+\n",
      "|  CREDIT_CARD_NO|      SSN|         CUST_EMAIL|CUST_PHONE|FIRST_NAME|MIDDLE_NAME|LAST_NAME|APT_NO|    STREET_NAME|  CUST_CITY|CUST_ZIP|CUST_STATE| CUST_COUNTRY|        LAST_UPDATED|npa|\n",
      "+----------------+---------+-------------------+----------+----------+-----------+---------+------+---------------+-----------+--------+----------+-------------+--------------------+---+\n",
      "|4210653347791178|123458703|RHorton@example.com|   1238106|      Russ|   Terrance|   Horton|    94| Carriage Drive| Canonsburg|   15317|        PA|United States|2018-04-21T12:49:...|412|\n",
      "|4210653376655865|123454594|CMedina@example.com|   1238106|     Carly|     Celina|   Medina|    76|Hillside Avenue|Monroeville|   15146|        PA|United States|2018-04-21T12:49:...|412|\n",
      "+----------------+---------+-------------------+----------+----------+-----------+---------+------+---------------+-----------+--------+----------+-------------+--------------------+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['724', '412']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.where(cust_df['CUST_PHONE'] == '1238106').show()\n",
    "area_code_pd.loc[area_code_pd['zipCode'] == \"15317\", 'npa_list'].iloc[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like '724' is available as an alternative.  Let's change one of the numbers to use this NPA number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = cust_df.withColumn('npa',\n",
    "            F.when((F.col(\"CUST_ZIP\") == \"15317\") & (F.col(\"CUST_PHONE\") == \"1238106\"), \"724\" )\\\n",
    "                .otherwise(F.col('npa')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+-----+\n",
      "|CUST_PHONE|npa|count|\n",
      "+----------+---+-----+\n",
      "|   1240339|310|    1|\n",
      "|   1241408|262|    1|\n",
      "|   1241213|310|    1|\n",
      "|   1239268|406|    1|\n",
      "|   1236077|469|    1|\n",
      "+----------+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.groupBy('CUST_PHONE','npa').count().orderBy(F.col('count').desc()).show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! No more duplicate phone numbers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the phone number to a (XXX)XXX-XXXX format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = cust_df.withColumn('CUST_PHONE',\n",
    "            F.format_string(\"(%s)%s-%s\", cust_df['npa'],\n",
    "            cust_df['CUST_PHONE'][0:3], cust_df['CUST_PHONE'][4:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|   CUST_PHONE|\n",
      "+-------------+\n",
      "|(601)123-7818|\n",
      "|(860)123-8933|\n",
      "|(224)124-3018|\n",
      "|(262)124-3215|\n",
      "|(915)124-2074|\n",
      "+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.select('CUST_PHONE').show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the emails column to see if they are all unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|count(DISTINCT CUST_EMAIL)|\n",
      "+--------------------------+\n",
      "|                       928|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.select(F.countDistinct(\"CUST_EMAIL\")).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strange, why are there so many duplicate emails?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|          CUST_EMAIL|count|\n",
      "+--------------------+-----+\n",
      "| ETruong@example.com|    2|\n",
      "| SCrouch@example.com|    2|\n",
      "|   BYork@example.com|    2|\n",
      "| DDorsey@example.com|    2|\n",
      "|  JEmery@example.com|    2|\n",
      "|   RHood@example.com|    2|\n",
      "|  MHatch@example.com|    2|\n",
      "|JGodfrey@example.com|    2|\n",
      "| RDeleon@example.com|    2|\n",
      "|SPadgett@example.com|    2|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.groupBy('CUST_EMAIL').count().orderBy(F.col('count').desc()).show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a sample email address and explore further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-------------+----------+-----------+\n",
      "|      SSN|       CUST_EMAIL|   CUST_PHONE|FIRST_NAME|MIDDLE_NAME|\n",
      "+---------+-----------------+-------------+----------+-----------+\n",
      "|123452454|BYork@example.com|(561)123-5377|    Bertie|   Mercedes|\n",
      "|123458062|BYork@example.com|(609)123-5585|    Buster|    Kirsten|\n",
      "+---------+-----------------+-------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.select('SSN','CUST_EMAIL','CUST_PHONE','FIRST_NAME','MIDDLE_NAME',).where(cust_df['CUST_EMAIL'] == 'BYork@example.com').show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: I really shouldn't alter emails since the email communication will not function if the email address isn't 100% correct.  \n",
    "\n",
    "But since two seemingly different people seem to be sharing the same email I can only assume the emails are made up and aren't actually used for communication.  \n",
    "\n",
    "So, as an exercise in data transformation, lets try to alter the emails so we have less unique email addresses.  My solution:  The emails seems to corresspond to the customer's first initial and last names.  But these combinations seems to overlap so lets differentiate the duplicate combinations by adding in a middle initial to the email address."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will use regex to extract the first letter of the customer's middle name and store it in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = cust_df.withColumn('Middle_Initial',F.format_string(\"%s\",cust_df['MIDDLE_NAME'][0:1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this new column looks and if it matches the middle name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|MIDDLE_NAME|Middle_Initial|\n",
      "+-----------+--------------+\n",
      "|         Wm|             W|\n",
      "|    Brendan|             B|\n",
      "|   Ezequiel|             E|\n",
      "|      Trina|             T|\n",
      "|        May|             M|\n",
      "+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.select('MIDDLE_NAME','Middle_Initial').show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's insert the Middle Initial into the second position of the email address by using the format_string function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = cust_df.withColumn('CUST_EMAIL', F.format_string(\"%s%s%s\", cust_df['CUST_EMAIL'][1:1],\n",
    "            cust_df['Middle_Initial'], cust_df['CUST_EMAIL'][2:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----------+---------+\n",
      "|          CUST_EMAIL|FIRST_NAME|MIDDLE_NAME|LAST_NAME|\n",
      "+--------------------+----------+-----------+---------+\n",
      "|AWHooper@example.com|      Alec|         Wm|   Hooper|\n",
      "|EBHolman@example.com|      Etta|    Brendan|   Holman|\n",
      "|WEDunham@example.com|    Wilber|   Ezequiel|   Dunham|\n",
      "| ETHardy@example.com|   Eugenio|      Trina|    Hardy|\n",
      "| WMAyers@example.com|   Wilfred|        May|    Ayers|\n",
      "+--------------------+----------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.select('CUST_EMAIL','FIRST_NAME','MIDDLE_NAME','LAST_NAME').show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many duplicate emails there are now.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|count(DISTINCT CUST_EMAIL)|\n",
      "+--------------------------+\n",
      "|                       951|\n",
      "+--------------------------+\n",
      "\n",
      "+--------------------+-----+\n",
      "|          CUST_EMAIL|count|\n",
      "+--------------------+-----+\n",
      "|KCBonner@example.com|    2|\n",
      "|LEGaines@example.com|    1|\n",
      "|AWHooper@example.com|    1|\n",
      "|HHMckinney@exampl...|    1|\n",
      "| JRMoody@example.com|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.select(F.countDistinct(\"CUST_EMAIL\")).show()\n",
    "cust_df.groupBy('CUST_EMAIL').count().orderBy(F.col('count').desc()).show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be one left.  We could eliminate the redudancy further by adding the second letter of the first or middle name into the email address but I will leave it as is for now."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next requirement is for the First and Last Names to be in Title Case, aka the first letter needs to be capitalized.  Let's use regex to see if that is the case in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|FIRST_NAME|\n",
      "+----------+\n",
      "+----------+\n",
      "\n",
      "+---------+\n",
      "|LAST_NAME|\n",
      "+---------+\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_name_filter = cust_df.filter(~F.col('FIRST_NAME').rlike('^[A-Z][a-z]+$'))\n",
    "l_name_filter = cust_df.filter(~F.col('LAST_NAME').rlike('^[A-Z][a-z]+$'))\n",
    "\n",
    "# ^[A-Z] checks to see if there is a single capital letter at the start of the string.\n",
    "# [a-z]+$ checks to see if there are only lower case letters after the first letter \n",
    "# and those letters also go on till the end of the string.  This eliminates the \n",
    "# possible matches of McCourt since the C cuts off the lower case letters.\n",
    "\n",
    "f_name_filter.select('FIRST_NAME').show()\n",
    "l_name_filter.select('LAST_NAME').show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to convert the middle names to lower case.  First let's see if we have any names that need to be converted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
